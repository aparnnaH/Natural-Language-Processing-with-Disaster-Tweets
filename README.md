# Natural Language Processing with Disaster Tweets
This project is about teaching a computer to figure out if a tweet is talking about a real disaster or not. People often tweet during emergencies, but not every tweet is actually about something serious happening. So, the challenge is to build a model that can tell the difference. The dataset we’re working with has about 10,000 tweets, and each one is tagged as either a real disaster tweet or just a regular tweet. Each tweet is just a piece of text, and they come in all shapes and sizes. The model has to pick up on clues in the words to decide if the tweet is genuinely about a disaster or not.

I started by exploring the dataset, which includes around 10,000 tweets. Each tweet comes with a label showing if it’s about a real disaster. From there, I cleaned up the text—removing links, punctuation, and stop words—to make it easier for the model to understand the important parts of each tweet. To turn the text into something a model can use, I used TF-IDF and also created tokenized sequences. Then I built an LSTM model using TensorFlow/Keras, which is great at understanding sequences like sentences or tweets. I trained the model and tested how well it performed using the F1 score, since this is a binary classification problem and we care about both precision and recall.
